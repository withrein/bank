import logging
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from typing import List, Dict, Optional, Any
import json

from models import CandidateScore, JobDescription, InterviewQuestion, CandidateQuestions, AgentState
from config import Config

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class InterviewAgent:
    """Enhanced Interview Agent with bilingual support for generating tailored interview questions"""
    
    def __init__(self):
        model_config = Config.get_current_model_config()
        self.llm = ChatOpenAI(
            model=model_config["model"],
            openai_api_key=model_config["api_key"],
            temperature=model_config["temperature"],
            max_tokens=model_config["max_tokens"]
        )
        self.mongolian_keywords = Config.get_language_keywords("mn")
        self.english_keywords = Config.get_language_keywords("en")
    
    def detect_language_preference(self, candidate: CandidateScore, job_description: JobDescription) -> str:
        """Detect preferred language for interview questions"""
        # Check job description language
        job_text = f"{job_description.title} {job_description.company} {job_description.description}".lower()
        
        # Count Cyrillic characters
        cyrillic_count = sum(1 for char in job_text if '\u0400' <= char <= '\u04FF')
        latin_count = sum(1 for char in job_text if char.isalpha() and ord(char) < 256)
        
        total_alpha = cyrillic_count + latin_count
        if total_alpha > 0 and (cyrillic_count / total_alpha) > 0.3:
            return "mn"
        
        # Check for Mongolian keywords in job description
        mongolian_keywords_found = sum(1 for keyword_list in self.mongolian_keywords.values() 
                                     for keyword in keyword_list if keyword in job_text)
        
        return "mn" if mongolian_keywords_found >= 2 else "en"
    
    def generate_questions_for_candidate(self, candidate: CandidateScore, 
                                       job_description: JobDescription) -> CandidateQuestions:
        """Generate tailored interview questions for a specific candidate with bilingual support"""
        try:
            logger.info(f"üé§ Generating interview questions for {candidate.candidate_name}")
            
            # Detect preferred language
            language = self.detect_language_preference(candidate, job_description)
            logger.info(f"üìù Using {'Mongolian' if language == 'mn' else 'English'} for questions")
            
            # Generate different types of questions
            technical_questions = self._generate_technical_questions(candidate, job_description, language)
            behavioral_questions = self._generate_behavioral_questions(candidate, job_description, language)
            role_specific_questions = self._generate_role_specific_questions(candidate, job_description, language)
            
            # Add general questions for cultural fit
            general_questions = self._generate_general_questions(candidate, job_description, language)
            
            total_questions = (len(technical_questions) + len(behavioral_questions) + 
                             len(role_specific_questions) + len(general_questions))
            
            candidate_questions = CandidateQuestions(
                candidate_name=candidate.candidate_name,
                job_title=job_description.title,
                technical_questions=technical_questions,
                behavioral_questions=behavioral_questions,
                role_specific_questions=role_specific_questions,
                total_questions=total_questions
            )
            
            logger.info(f"‚úÖ Generated {total_questions} questions for {candidate.candidate_name}")
            return candidate_questions
            
        except Exception as e:
            logger.error(f"‚ùå Error generating questions for {candidate.candidate_name}: {str(e)}")
            # Return minimal questions set
            return CandidateQuestions(
                candidate_name=candidate.candidate_name,
                job_title=job_description.title,
                technical_questions=[],
                behavioral_questions=[],
                role_specific_questions=[],
                total_questions=0
            )
    
    def _generate_technical_questions(self, candidate: CandidateScore, 
                                    job_description: JobDescription, language: str = "en") -> List[InterviewQuestion]:
        """Generate technical questions with bilingual support"""
        
        if language == "mn":
            system_prompt = """–¢–∞ –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω —Ç–µ—Ö–Ω–∏–∫–∏–π–Ω —è—Ä–∏–ª—Ü–ª–∞–≥–∞ –∞–≤–¥–∞–≥ –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω —é–º. –ê–∂–∏–ª—Ç–Ω—ã –º—ç–¥–ª—ç–≥ —á–∞–¥–≤–∞—Ä –±–æ–ª–æ–Ω –∞–∂–ª—ã–Ω —à–∞–∞—Ä–¥–ª–∞–≥–∞–¥ —Ç—É–ª–≥—É—É—Ä–ª–∞–Ω —Ç–µ—Ö–Ω–∏–∫–∏–π–Ω –∞—Å—É—É–ª—Ç—É—É–¥ “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø.

–î–∞—Ä–∞–∞—Ö JSON —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É:
[
    {
        "question": "–ë–æ–¥–∏—Ç —è—Ä–∏–ª—Ü–ª–∞–≥—ã–Ω –∞—Å—É—É–ª—Ç",
        "category": "technical",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["–ì–æ–ª —Å–∞–Ω–∞–∞ 1", "–ì–æ–ª —Å–∞–Ω–∞–∞ 2", "–ì–æ–ª —Å–∞–Ω–∞–∞ 3"]
    }
]

3-5 —Ç–µ—Ö–Ω–∏–∫–∏–π–Ω –∞—Å—É—É–ª—Ç “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø:
1. –ê–∂–∏–ª—Ç–Ω—ã —Ç–µ—Ö–Ω–∏–∫–∏–π–Ω —á–∞–¥–≤–∞—Ä—ã–≥ —à–∞–ª–≥–∞—Ö
2. –ê–∂–ª—ã–Ω —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π
3. –¢“Ø–≤—à–Ω–∏–π —Ö—É–≤—å–¥ –æ–ª–æ–Ω —è–Ω–∑ –±–∞–π—Ö (–∞–º–∞—Ä—Ö–∞–Ω, –¥—É–Ω–¥, —Ö“Ø–Ω–¥)
4. –û–Ω–æ–ª—ã–Ω –±–∏—à, –ø—Ä–∞–∫—Ç–∏–∫ —Ö—ç—Ä—ç–≥–ª—ç—ç–Ω–¥ —á–∏–≥–ª—ç—Å—ç–Ω
5. –ê–∂–∏–ª—Ç–Ω—ã —Ç—É—Ä—à–ª–∞–≥—ã–Ω —Ç“Ø–≤—à–∏–Ω–¥ —Ç–æ—Ö–∏—Ä—Å–æ–Ω

–•—ç—Ä—ç–≤ –∞–∂–∏–ª—Ç–∞–Ω–¥ —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —á–∞–¥–≤–∞—Ä –¥—É—Ç—É—É –±–∞–π–≤–∞–ª —Ç—ç—Ä —Ç–∞–ª–∞–∞—Ä –∞—Å—É—É–ª—Ç –æ—Ä—É—É–ª–Ω–∞ —É—É."""
            
            context = f"""
–ê–ñ–ò–õ–¢–ù–´ –ú–≠–î–≠–≠–õ–≠–õ:
- –ù—ç—Ä: {candidate.candidate_name}
- –¢–æ—Ö–∏—Ä—Å–æ–Ω —á–∞–¥–≤–∞—Ä: {', '.join(candidate.matched_skills) if candidate.matched_skills else '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –î—É—Ç—É—É —á–∞–¥–≤–∞—Ä: {', '.join(candidate.missing_skills) if candidate.missing_skills else '–ë–∞–π—Ö–≥“Ø–π'}
- –î–∞–≤—É—É —Ç–∞–ª: {', '.join(candidate.strengths) if candidate.strengths else '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –ù–∏–π—Ç –æ–Ω–æ–æ: {candidate.overall_score:.1f}/100

–ê–ñ–õ–´–ù –®–ê–ê–†–î–õ–ê–ì–ê:
- –ê–ª–±–∞–Ω —Ç—É—à–∞–∞–ª: {job_description.title}
- –®–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —á–∞–¥–≤–∞—Ä: {', '.join(job_description.required_skills) if job_description.required_skills else '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –•“Ø—Å—Å—ç–Ω —á–∞–¥–≤–∞—Ä: {', '.join(job_description.preferred_skills) if job_description.preferred_skills else '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –•–∞–º–≥–∏–π–Ω –±–∞–≥–∞ —Ç—É—Ä—à–ª–∞–≥–∞: {job_description.min_experience or '–ó–∞–∞–≥–∞–∞–≥“Ø–π'} –∂–∏–ª

–≠–Ω—ç –∞–∂–∏–ª—Ç–∞–Ω–¥ —Ç–µ—Ö–Ω–∏–∫–∏–π–Ω –∞—Å—É—É–ª—Ç “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø."""
        else:
            system_prompt = """You are an expert technical interviewer. Generate technical interview questions based on the candidate's background and job requirements.

Return your response as a JSON array of question objects with this structure:
[
    {
        "question": "The actual interview question",
        "category": "technical",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["Key point 1", "Key point 2", "Key point 3"]
    }
]

Generate 3-5 technical questions that:
1. Test the candidate's claimed technical skills
2. Are relevant to the job requirements
3. Vary in difficulty (mix of easy, medium, hard)
4. Focus on practical application rather than just theory
5. Consider the candidate's experience level
6. Include questions about missing skills to assess learning ability

If the candidate has gaps in required skills, include questions that explore those areas."""
            
            context = f"""
CANDIDATE PROFILE:
- Name: {candidate.candidate_name}
- Matched Skills: {', '.join(candidate.matched_skills) if candidate.matched_skills else 'None specified'}
- Missing Skills: {', '.join(candidate.missing_skills) if candidate.missing_skills else 'None'}
- Strengths: {', '.join(candidate.strengths) if candidate.strengths else 'None specified'}
- Overall Score: {candidate.overall_score:.1f}/100

JOB REQUIREMENTS:
- Title: {job_description.title}
- Required Skills: {', '.join(job_description.required_skills) if job_description.required_skills else 'None specified'}
- Preferred Skills: {', '.join(job_description.preferred_skills) if job_description.preferred_skills else 'None specified'}
- Min Experience: {job_description.min_experience or 'Not specified'} years

Generate technical interview questions for this candidate."""

        return self._get_questions_from_llm(system_prompt, context, "technical")
    
    def _generate_behavioral_questions(self, candidate: CandidateScore, 
                                     job_description: JobDescription, language: str = "en") -> List[InterviewQuestion]:
        """Generate behavioral questions with bilingual support"""
        
        if language == "mn":
            system_prompt = """–¢–∞ HR –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω —é–º. STAR –∞—Ä–≥—ã–≥ –∞—à–∏–≥–ª–∞–Ω (–ù”©—Ö—Ü”©–ª –±–∞–π–¥–∞–ª, –î–∞–∞–ª–≥–∞–≤–∞—Ä, “Æ–π–ª–¥—ç–ª, “Æ—Ä –¥“Ø–Ω) –∑–∞–Ω —Ç”©–ª”©–≤–∏–π–Ω –∞—Å—É—É–ª—Ç—É—É–¥ “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø.

–î–∞—Ä–∞–∞—Ö JSON —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É:
[
    {
        "question": "–ë–æ–¥–∏—Ç —è—Ä–∏–ª—Ü–ª–∞–≥—ã–Ω –∞—Å—É—É–ª—Ç",
        "category": "behavioral",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["–ì–æ–ª —Å–∞–Ω–∞–∞ 1", "–ì–æ–ª —Å–∞–Ω–∞–∞ 2", "–ì–æ–ª —Å–∞–Ω–∞–∞ 3"]
    }
]

3-4 –∑–∞–Ω —Ç”©–ª”©–≤–∏–π–Ω –∞—Å—É—É–ª—Ç “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø:
1. –ê–∂–∏–ª—Ç–Ω—ã ”©–º–Ω”©—Ö —Ç—É—Ä—à–ª–∞–≥–∞, –∑–∞–Ω —Ç”©–ª”©–≤–∏–π–≥ —Å—É–¥–ª–∞—Ö
2. –ê–∂–ª—ã–Ω —à–∞–∞—Ä–¥–ª–∞–≥–∞, –∫–æ–º–ø–∞–Ω–∏–π–Ω —Å–æ—ë–ª—Ç–æ–π —Ö–æ–ª–±–æ–æ—Ç–æ–π
3. "–¢–∞–Ω–¥ ... –Ω”©—Ö—Ü”©–ª –±–∞–π–¥–∞–ª —Ç–æ—Ö–∏–æ–ª–¥—Å–æ–Ω —Ç—É—Ö–∞–π —è—Ä–∏–Ω–∞ —É—É" —Ö—ç–ª–±—ç—Ä—Ç—ç–π
4. –£–¥–∏—Ä–¥–ª–∞–≥–∞, –∞—Å—É—É–¥–∞–ª —à–∏–π–¥—ç—Ö, –±–∞–≥–∞–∞—Ä –∞–∂–∏–ª–ª–∞—Ö —á–∞–¥–≤–∞—Ä—Ç —á–∏–≥–ª—ç—Å—ç–Ω
5. –ê–∂–∏–ª—Ç–Ω—ã –¥–∞–≤—É—É —Ç–∞–ª, —Å—É–ª —Ç–∞–ª—ã–≥ —Ö–∞—Ä–≥–∞–ª–∑–∞–Ω"""
            
            context = f"""
–ê–ñ–ò–õ–¢–ù–´ –ú–≠–î–≠–≠–õ–≠–õ:
- –ù—ç—Ä: {candidate.candidate_name}
- –î–∞–≤—É—É —Ç–∞–ª: {', '.join(candidate.strengths) if candidate.strengths else '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –°—É–ª —Ç–∞–ª: {', '.join(candidate.weaknesses) if candidate.weaknesses else '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –ó”©–≤–ª”©–º–∂: {candidate.recommendation}

–ê–ñ–õ–´–ù –®–ê–ê–†–î–õ–ê–ì–ê:
- –ê–ª–±–∞–Ω —Ç—É—à–∞–∞–ª: {job_description.title}
- –ö–æ–º–ø–∞–Ω–∏: {job_description.company}
- “Æ–Ω–¥—Å—ç–Ω “Ø“Ø—Ä—ç–≥: {', '.join(job_description.responsibilities) if job_description.responsibilities else '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}

–≠–Ω—ç –∞–∂–∏–ª—Ç–∞–Ω–¥ –∑–∞–Ω —Ç”©–ª”©–≤–∏–π–Ω –∞—Å—É—É–ª—Ç “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø."""
        else:
            system_prompt = """You are an expert HR interviewer. Generate behavioral interview questions using the STAR method (Situation, Task, Action, Result).

Return your response as a JSON array of question objects with this structure:
[
    {
        "question": "The actual interview question",
        "category": "behavioral",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["Key point 1", "Key point 2", "Key point 3"]
    }
]

Generate 3-4 behavioral questions that:
1. Explore the candidate's past experiences and behaviors
2. Are relevant to the job requirements and company culture
3. Use the "Tell me about a time when..." format
4. Focus on key competencies like leadership, problem-solving, teamwork, communication
5. Consider the candidate's strengths and potential weaknesses
6. Include questions about handling challenges and conflicts"""

            context = f"""
CANDIDATE PROFILE:
- Name: {candidate.candidate_name}
- Strengths: {', '.join(candidate.strengths) if candidate.strengths else 'None specified'}
- Weaknesses: {', '.join(candidate.weaknesses) if candidate.weaknesses else 'None specified'}
- Recommendation: {candidate.recommendation}

JOB REQUIREMENTS:
- Title: {job_description.title}
- Company: {job_description.company}
- Key Responsibilities: {', '.join(job_description.responsibilities) if job_description.responsibilities else 'Not specified'}

Generate behavioral interview questions for this candidate."""

        return self._get_questions_from_llm(system_prompt, context, "behavioral")
    
    def _generate_role_specific_questions(self, candidate: CandidateScore, 
                                        job_description: JobDescription, language: str = "en") -> List[InterviewQuestion]:
        """Generate role-specific questions with bilingual support"""
        
        if language == "mn":
            system_prompt = """–¢–∞ —Ç—É—Å –∞–∂–ª—ã–Ω –±–∞–π—Ä–∞–Ω–¥ –º—ç—Ä–≥—ç—à—Å—ç–Ω —è—Ä–∏–ª—Ü–ª–∞–≥–∞ –∞–≤–¥–∞–≥ –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω —é–º. –ê–∂–ª—ã–Ω —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ–ª—Ç –±–æ–ª–æ–Ω –∞–∂–∏–ª—Ç–Ω—ã –º—ç–¥–ª—ç–≥—Ç —Ç—É–ª–≥—É—É—Ä–ª–∞–Ω —Ç—É—Ö–∞–π–Ω –∞–ª–±–∞–Ω —Ç—É—à–∞–∞–ª–¥ –∑–æ—Ä–∏—É–ª—Å–∞–Ω –∞—Å—É—É–ª—Ç—É—É–¥ “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø.

–î–∞—Ä–∞–∞—Ö JSON —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É:
[
    {
        "question": "–ë–æ–¥–∏—Ç —è—Ä–∏–ª—Ü–ª–∞–≥—ã–Ω –∞—Å—É—É–ª—Ç",
        "category": "role-specific",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["–ì–æ–ª —Å–∞–Ω–∞–∞ 1", "–ì–æ–ª —Å–∞–Ω–∞–∞ 2", "–ì–æ–ª —Å–∞–Ω–∞–∞ 3"]
    }
]

2-3 –∞–ª–±–∞–Ω —Ç—É—à–∞–∞–ª–¥ –∑–æ—Ä–∏—É–ª—Å–∞–Ω –∞—Å—É—É–ª—Ç “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø:
1. –¢—É—Ö–∞–π–Ω –∞–∂–∏–ª, —Ç“Ø“Ø–Ω–∏–π —Å–æ—Ä–∏–ª—Ç—ã–≥ –æ–π–ª–≥–æ–∂ –±–∞–π–≥–∞–∞–≥ —à–∞–ª–≥–∞—Ö
2. –°–∞–ª–±–∞—Ä—ã–Ω –º—ç–¥–ª—ç–≥, —á–∏–≥ —Ö–∞–Ω–¥–ª–∞–≥—ã–≥ —Å—É–¥–ª–∞—Ö
3. –°–æ—ë–ª—ã–Ω —Ç–æ—Ö–∏—Ä–æ–ª, —Å—ç–¥—ç–ª –∑–æ—Ä–∏–ª–≥—ã–≥ “Ø–Ω—ç–ª—ç—Ö
4. –¢—É—Å –∞–ª–±–∞–Ω —Ç—É—à–∞–∞–ª, –∫–æ–º–ø–∞–Ω–∏–¥ —Ç—É—Å–≥–∞–π–ª–∞–Ω –∑–æ—Ä–∏—É–ª—Å–∞–Ω
5. –ê–∂–∏–ª—Ç–Ω—ã —ç–Ω—ç –∞–∂–∏–ª–¥ –∂–∏–Ω—Ö—ç–Ω—ç —Å–æ–Ω–∏—Ä—Ö–æ–ª –±–∞–π–≥–∞–∞–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö"""
            
            context = f"""
–ê–ñ–ò–õ–¢–ù–´ –ú–≠–î–≠–≠–õ–≠–õ:
- –ù—ç—Ä: {candidate.candidate_name}
- –ù–∏–π—Ç –æ–Ω–æ–æ: {candidate.overall_score:.1f}/100
- –ó”©–≤–ª”©–º–∂: {candidate.recommendation}

–ê–ñ–õ–´–ù –î–≠–õ–ì–≠–†–≠–ù–ì“Æ–ô:
- –ê–ª–±–∞–Ω —Ç—É—à–∞–∞–ª: {job_description.title}
- –ö–æ–º–ø–∞–Ω–∏: {job_description.company}
- –ë–∞–π—Ä—à–∏–ª: {job_description.location or '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –ê–∂–ª—ã–Ω —Ç”©—Ä”©–ª: {job_description.job_type or '–ó–∞–∞–≥–∞–∞–≥“Ø–π'}
- –¢–æ–¥–æ—Ä—Ö–æ–π–ª–æ–ª—Ç: {job_description.description[:300]}...

–≠–Ω—ç –∞–ª–±–∞–Ω —Ç—É—à–∞–∞–ª–¥ –∑–æ—Ä–∏—É–ª—Å–∞–Ω –∞—Å—É—É–ª—Ç “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø."""
        else:
            system_prompt = """You are an expert interviewer for this specific role. Generate role-specific interview questions that test the candidate's understanding of the role and industry.

Return your response as a JSON array of question objects with this structure:
[
    {
        "question": "The actual interview question",
        "category": "role-specific",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["Key point 1", "Key point 2", "Key point 3"]
    }
]

Generate 2-3 role-specific questions that:
1. Test understanding of the specific role and its challenges
2. Explore industry knowledge and current trends
3. Assess cultural fit and motivation
4. Are tailored to this specific position and company
5. Help determine if the candidate is genuinely interested in this role
6. Explore their vision for the role and potential contributions"""

            context = f"""
CANDIDATE PROFILE:
- Name: {candidate.candidate_name}
- Overall Score: {candidate.overall_score:.1f}/100
- Recommendation: {candidate.recommendation}

JOB DETAILS:
- Title: {job_description.title}
- Company: {job_description.company}
- Location: {job_description.location or 'Not specified'}
- Job Type: {job_description.job_type or 'Not specified'}
- Description: {job_description.description[:300]}...

Generate role-specific interview questions for this position."""

        return self._get_questions_from_llm(system_prompt, context, "role-specific")
    
    def _generate_general_questions(self, candidate: CandidateScore, 
                                  job_description: JobDescription, language: str = "en") -> List[InterviewQuestion]:
        """Generate general questions for cultural fit and motivation"""
        
        if language == "mn":
            system_prompt = """–¢–∞ –µ—Ä”©–Ω—Ö–∏–π —è—Ä–∏–ª—Ü–ª–∞–≥–∞ –∞–≤–¥–∞–≥ –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω —é–º. –°–æ—ë–ª—ã–Ω —Ç–æ—Ö–∏—Ä–æ–ª, —Å—ç–¥—ç–ª –∑–æ—Ä–∏–ª–≥—ã–≥ “Ø–Ω—ç–ª—ç—Ö –µ—Ä”©–Ω—Ö–∏–π –∞—Å—É—É–ª—Ç—É—É–¥ “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø.

–î–∞—Ä–∞–∞—Ö JSON —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É:
[
    {
        "question": "–ë–æ–¥–∏—Ç —è—Ä–∏–ª—Ü–ª–∞–≥—ã–Ω –∞—Å—É—É–ª—Ç",
        "category": "general",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["–ì–æ–ª —Å–∞–Ω–∞–∞ 1", "–ì–æ–ª —Å–∞–Ω–∞–∞ 2", "–ì–æ–ª —Å–∞–Ω–∞–∞ 3"]
    }
]

2-3 –µ—Ä”©–Ω—Ö–∏–π –∞—Å—É—É–ª—Ç “Ø“Ø—Å–≥—ç–Ω—ç “Ø“Ø:
1. –°–æ—ë–ª—ã–Ω —Ç–æ—Ö–∏—Ä–æ–ª “Ø–Ω—ç–ª—ç—Ö
2. –£—Ä—Ç —Ö—É–≥–∞—Ü–∞–∞–Ω—ã –∑–æ—Ä–∏–ª–≥–æ —Å—É–¥–ª–∞—Ö
3. –ê–∂–ª—ã–Ω —Å—ç–¥—ç–ª, —ç–Ω–µ—Ä–≥–∏ “Ø–Ω—ç–ª—ç—Ö
4. –ë–∞–≥—Ç–∞–π —Ö–∞–º—Ç—Ä–∞–Ω –∞–∂–∏–ª–ª–∞—Ö —á–∞–¥–≤–∞—Ä
5. ”®”©—Ä”©”© –¥—ç—ç—à–ª“Ø“Ø–ª—ç—Ö —Ö“Ø—Å—ç–ª —ç—Ä–º—ç–ª–∑—ç–ª"""
        else:
            system_prompt = """You are an interviewer focusing on cultural fit and general motivation. Generate general interview questions.

Return your response as a JSON array of question objects with this structure:
[
    {
        "question": "The actual interview question",
        "category": "general",
        "difficulty": "easy|medium|hard",
        "expected_answer_points": ["Key point 1", "Key point 2", "Key point 3"]
    }
]

Generate 2-3 general questions that:
1. Assess cultural fit with the company
2. Explore long-term career goals
3. Evaluate work motivation and energy
4. Test collaboration and communication skills
5. Understand self-improvement mindset"""

        context_base = f"""
CANDIDATE: {candidate.candidate_name}
COMPANY: {job_description.company}
ROLE: {job_description.title}
"""

        return self._get_questions_from_llm(system_prompt, context_base, "general")
    
    def _get_questions_from_llm(self, system_prompt: str, context: str, category: str) -> List[InterviewQuestion]:
        """Get questions from LLM and parse them with improved error handling"""
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=context)
            ]
            
            response = self.llm.invoke(messages)
            response_text = response.content.strip()
            
            # Try to extract JSON from response
            json_start = response_text.find('[')
            json_end = response_text.rfind(']') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                questions_data = json.loads(json_text)
            else:
                questions_data = json.loads(response_text)
            
            # Convert to InterviewQuestion objects
            questions = []
            for q_data in questions_data:
                if isinstance(q_data, dict) and 'question' in q_data:
                    question = InterviewQuestion(
                        question=q_data.get('question', ''),
                        category=q_data.get('category', category),
                        difficulty=q_data.get('difficulty', 'medium'),
                        expected_answer_points=q_data.get('expected_answer_points', [])
                    )
                    questions.append(question)
            
            return questions
            
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing LLM JSON response for {category} questions: {str(e)}")
            return self._get_fallback_questions(category)
        except Exception as e:
            logger.error(f"Error with LLM for {category} questions: {str(e)}")
            return self._get_fallback_questions(category)
    
    def _get_fallback_questions(self, category: str) -> List[InterviewQuestion]:
        """Get fallback questions when LLM fails"""
        fallback_questions = {
            "technical": [
                InterviewQuestion(
                    question="Can you walk me through your approach to solving a complex technical problem?",
                    category="technical",
                    difficulty="medium",
                    expected_answer_points=["Problem analysis", "Solution design", "Implementation", "Testing"]
                )
            ],
            "behavioral": [
                InterviewQuestion(
                    question="Tell me about a time when you had to work with a difficult team member.",
                    category="behavioral",
                    difficulty="medium",
                    expected_answer_points=["Situation description", "Actions taken", "Outcome", "Lessons learned"]
                )
            ],
            "role-specific": [
                InterviewQuestion(
                    question="What interests you most about this particular role?",
                    category="role-specific",
                    difficulty="easy",
                    expected_answer_points=["Role understanding", "Personal motivation", "Alignment with skills"]
                )
            ],
            "general": [
                InterviewQuestion(
                    question="Where do you see yourself in 5 years?",
                    category="general",
                    difficulty="easy",
                    expected_answer_points=["Career vision", "Growth mindset", "Alignment with company"]
                )
            ]
        }
        
        return fallback_questions.get(category, [])
    
    def generate_questions_for_all_candidates(self, shortlisted_candidates: List[CandidateScore], 
                                           job_description: JobDescription) -> Dict[str, CandidateQuestions]:
        """Generate interview questions for all shortlisted candidates"""
        all_questions = {}
        
        logger.info(f"üé§ Generating interview questions for {len(shortlisted_candidates)} shortlisted candidates")
        
        for i, candidate in enumerate(shortlisted_candidates, 1):
            logger.info(f"üìù Processing candidate {i}/{len(shortlisted_candidates)}: {candidate.candidate_name}")
            candidate_questions = self.generate_questions_for_candidate(candidate, job_description)
            all_questions[candidate.candidate_name] = candidate_questions
        
        logger.info(f"‚úÖ Completed generating interview questions for all candidates")
        
        # Log summary
        total_questions = sum(q.total_questions for q in all_questions.values())
        logger.info(f"üìä Total questions generated: {total_questions}")
        
        return all_questions
    
    def process(self, state: AgentState) -> AgentState:
        """Process interview question generation in the agent state"""
        if not state.shortlisted_candidates:
            state.errors.append("No shortlisted candidates available for interview question generation")
            return state
        
        if not state.job_description:
            state.errors.append("No job description available for interview question generation")
            return state
        
        try:
            logger.info("üé§ Interview Agent: Starting interview question generation...")
            state.current_step = "generating_questions"
            
            # Generate questions for all shortlisted candidates
            interview_questions = self.generate_questions_for_all_candidates(
                state.shortlisted_candidates, 
                state.job_description
            )
            state.interview_questions = interview_questions
            
            logger.info(f"‚úÖ Interview Agent: Successfully generated questions for {len(interview_questions)} candidates")
            
            # Log questions summary
            for candidate_name, questions in interview_questions.items():
                logger.info(f"   - {candidate_name}: {questions.total_questions} questions")
                logger.info(f"     Technical: {len(questions.technical_questions)}, "
                          f"Behavioral: {len(questions.behavioral_questions)}, "
                          f"Role-specific: {len(questions.role_specific_questions)}")
            
            state.current_step = "questions_generated"
            
        except Exception as e:
            error_msg = f"Interview Agent error: {str(e)}"
            logger.error(f"‚ùå {error_msg}")
            state.errors.append(error_msg)
        
        return state 